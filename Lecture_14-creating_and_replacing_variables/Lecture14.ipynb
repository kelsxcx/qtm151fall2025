{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\"> Lecture 14 - Creating/replacing variables.</span>\n",
    "\n",
    "<font size = \"5\">\n",
    "\n",
    "- Starting a new module on **manipulating data** in Pandas\n",
    "- Will discuss adding new columns/variables to a DataFrame (data set)\n",
    "- Will cover **cleaning** data and **recoding** variables"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\"> I. Import Libraries and Data </span>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"5\">\n",
    "Key libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"5\">\n",
    "\n",
    "Read dataset of car racing circuits\n",
    "\n",
    "- https://en.wikipedia.org/wiki/Formula_One <br>\n",
    "- [See Data Source](https://www.kaggle.com/datasets/rohanrao/formula-1-world-championship-1950-2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circuits = pd.read_csv(\"data_raw/circuits.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\"> II. Examine Data </span>\n",
    "\n",
    "<font size = \"4\">\n",
    "Can view DataFrame using the DataWrangler extension on VS code. But information about the data can be accessed using Pandas commands "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column/variable headings\n",
    "print(circuits.columns.values)\n",
    "print()\n",
    "# number of rows and columns of DataFrame\n",
    "print(circuits.shape)\n",
    "print()\n",
    "n_rows, n_cols = circuits.shape\n",
    "print(\"# of rows:\", n_rows)\n",
    "print(\"# of columns:\", n_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"4\">\n",
    "\n",
    "We can also get the DataTypes for each column (dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(circuits.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"4\">\n",
    "\n",
    "We've seen \"circuits.apply\", \"circuits.shape\", \"circuits.dtypes\", which are all **attributes** of the Pandas DataFrame we named \"circuits\"\n",
    "\n",
    "The DataFrame also has **methods** (functions), like \"circuits.apply\" and \"circuits.mean\".\n",
    "\n",
    "How do we remember all of these?\n",
    "\n",
    "VS code can remind you of all available attributes and methods for an object. In the code cell below, type \"circuits.\" (with the period) and then wait, without running the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type the following (including the period), then wait, without running the cell\n",
    "# type this >> circuits.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"4\">\n",
    "\n",
    "**Note:** We've already seen how to add new columns/variables to a DataFrame. But we haven't seen how to rename the existing columns/variables. Some of the most straightforward are shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the first and last column headings\n",
    "print(circuits.columns.values)\n",
    "print()\n",
    "\n",
    "# Change last heading to \"Uniform Resource Locator\"\n",
    "circuits.columns.values[-1] = \"Uniform Resource Locator\"\n",
    "\n",
    "# Change first heading to \"ID_No\"\n",
    "circuits.columns.values[0] = \"ID_No\"\n",
    "print(circuits.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change back to \"url\" \n",
    "\n",
    "# Create a new data-frame and assign it to \"circuits\". \n",
    "# So we're overwriting the dataframe.\n",
    "circuits = circuits.rename(columns={'Uniform Resource Locator': 'url'})\n",
    "\n",
    "print(circuits.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change back to \"circuitID\"\n",
    "\n",
    "# Instead of making a new dataframe and over-writing the old one, change it \"in-place\"\n",
    "circuits.rename(columns={'ID_No':'circuitID'}, inplace=True)\n",
    "\n",
    "print(circuits.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\"> III. Cleaning Data </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"5\">\n",
    "\n",
    "Data that should be numerical (e.g. altitude of a Formula One track) can have missing values or non-numerical replacements (like \"N/A\"). We want to manipulate the data to allow for numerical calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(circuits[\"lat\"].mean())\n",
    "print(circuits[\"lng\"].mean())\n",
    "print(circuits[\"alt\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try to figure out the problem\n",
    "print(circuits.dtypes)\n",
    "\n",
    "# The column \"alt\" has the DataType \"object\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(circuits[\"alt\"])\n",
    "# these look like numbers, except the last two are \"\\N\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"4\">\n",
    "\n",
    "- Each column of a Pandas DataFrame is a Pandas Series\n",
    "- Each Pandas Series with \"dtype: object\" has a collection of methods known as \"String Methods\"\n",
    "- To execute a method from this collection you must type: ``series_name.str.method_name``\n",
    "- **NOTE**: Whenever I type something with a vague placeholder name like \"series_name\" or \"method_name\" this means that you should replace that word/phrase with an actual Python object or method/function name\n",
    "- Within this collection, there is a method we want to use called ``.isnumeric``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a Pandas Series\n",
    "print(type(circuits[\"alt\"])) \n",
    "print()\n",
    "# This is a Pandas StringMethods object (collection of methods/functions)\n",
    "print(type(circuits[\"alt\"].str)) \n",
    "print()\n",
    "# This is a method/function belonging to the StringMethods collection\n",
    "print(type(circuits[\"alt\"].str.isnumeric)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"4\">\n",
    "\n",
    "You'll get an error if you try to use ``.str`` with a column that doesn't have the \"object\" dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circuits[\"lat\"].str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"4\">\n",
    "\n",
    "The ``series_name.str.isnumeric()`` method returns a Pandas Series with ``True`` everywhere the Series entry is deemed \"numeric\" and ``False`` otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(circuits[\"alt\"].str.isnumeric())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can reference subattributes of columns in \".query()\"\n",
    "non_numeric = circuits.query(\"  alt.str.isnumeric() == False \")\n",
    "print(non_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"4\">\n",
    "\n",
    "Why is the string \"-7\" considered non-numeric?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The pd.unique() function extracts unique values from a series/array\n",
    "\n",
    "unique_non_numeric = pd.unique( non_numeric[\"alt\"] )\n",
    "print(unique_non_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"4\">\n",
    "\n",
    "We'll decide what we should replace \"\\N\" and \"-7\" with\n",
    "\n",
    "- \"-7\" is easy. We'll replace the string \"-7\" with the integer -7\n",
    "- What about \"\\N\"? It turns out the best choice is the \"nan\" (not a number) object from the Numpy library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.nan)\n",
    "\n",
    "# ironically, the type of this object is a floating-point number...\n",
    "print(type(np.nan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_non_numeric is the list with [\"\\\\N\", \"-7\"]\n",
    "# we'll make a list of the same length with the values we want to replace them with\n",
    "\n",
    "replace_vals = [np.nan, -7]\n",
    "\n",
    "# Overwrite the \"alt\" column, replacing every appearance from unique_non_numeric with\n",
    "# the corresponding element of replace_vals\n",
    "circuits[\"alt\"] = circuits[\"alt\"].replace(unique_non_numeric, replace_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"4\">\n",
    "\n",
    "Did it work? Let's test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_numeric = circuits.query(\"  alt.str.isnumeric() == False  \")\n",
    "print(non_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"4\">\n",
    "\n",
    "There are no rows with a non-numeric value for \"alt\"! Are we done? (No)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(circuits[\"alt\"].mean()) # get an error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"4\">\n",
    "\n",
    "What happened? We still don't have the right \"dtype\" to do calculations. We should have checked that in the first place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(circuits.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"4\">\n",
    "\n",
    "The \"alt\" column still has the \"object\" dtype. But since we've cleaned the data, all of its elements **can be** converted to numeric values. The ``Pandas`` function ``to_numeric`` can be used to do this.\n",
    "\n",
    "We'll create a new column to the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circuits[\"alt_numeric\"] = pd.to_numeric(circuits[\"alt\"])\n",
    "print(circuits[\"alt_numeric\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After the cleaning process is done, you may want to store the dataset again\n",
    "# It's recommended to do this in a separate file from the original\n",
    "# That way you can always go back to the original if you made a programming error\n",
    "\n",
    "circuits.to_csv(\"data_clean/circuits.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"4\">\n",
    "\n",
    "**Exercise**: When I was creating this notebook, I had the following question. \"If I read in the .csv file I just created and save it as a new DataFrame, will I have to re-do any part of the cleaning process?\" Test this out for yourself.\n",
    "\n",
    "**Exercise**: Read in the .csv file that was just created, saving it as a new DataFrame. You'll see there is an extra column/variable called \"Unnamed\" with the values 0, 1, 2, ..., 75, 76. Type ``help(circuits.to_csv)`` to figure out how to create a new .csv file without this extra column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"4\">\n",
    "\n",
    "**Exercise:**\n",
    "\n",
    "- Use \".replace()\" with the \"country\" column\n",
    "- Replace \"USA\" with \"United States\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your own code\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\"> IV. Recoding Variables</span>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"4\">\n",
    "\n",
    "\"Recoding\" variables means changing/re-expressing existing variables into a new set of values that may be more useful for data analysis.\n",
    "\n",
    "Examples:\n",
    "\n",
    "- A variable called \"age\" consists of integers beginning at 0 (how old the person is in terms of years). We can transform this into a categorical variable with the values \"child\", \"teenager\", \"young adult\", \"adult\", \"senior\"\n",
    "\n",
    "- A variable called \"submission_time\" records the time that a student submitted an assignment to Gradescope. We can transform this into a categorical variable with the values \"on time\" and \"late\"\n",
    "\n",
    "- A variable called \"candidate_preference\" is taken from a survey of people asking which of two presidential candidates they will vote for. This is a categorical variable with the values \"Candidate A\", \"Candidate B\", \"Don't Know\", \"Refused\", \"Blank\", \"Other Candidate\". This is recoded to another categorical variable with only 3 values \"Candidate A\", \"Candidate B\", and \"Neither\".\n",
    "\n",
    "- We convert a variable \"height\" measured in inches, to a corresponding variable measuring height in centimeters.\n",
    "\n",
    "- A variable called \"lat\" consists of floating point numbers consisting of a geographical coordinate measuring the distance north or south of the Equator. We change this into a categorical variable with the values \"north\" or \"south\".\n",
    "\n",
    "We'll perform this last one in 3 different ways. In each way, we will consider as \"south\" those circuits with $-90 < \\textrm{lat} \\leq 0$ and \"north\" as circuits with $0 < \\textrm{lat} \\leq 90$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows, ncols = circuits.shape \n",
    "\n",
    "col_no = 5 # column 5 is \"lat\"\n",
    "hemisphere = []\n",
    "\n",
    "for k in range(nrows):\n",
    "    lat_val = circuits.iloc[k, col_no]\n",
    "    if lat_val <= 0:\n",
    "        hemisphere.append(\"South\")\n",
    "    else:\n",
    "        hemisphere.append(\"North\")\n",
    "\n",
    "# could overwrite \"lat\", but is almost always better to keep the original variable\n",
    "circuits[\"hemisphere\"] = hemisphere\n",
    "\n",
    "# Note: I made sure the data in this column didn't need to be cleaned first!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the column to verify the next cell actually works\n",
    "circuits[\"hemisphere\"] = \"N/A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_hemisphere(lat):\n",
    "    if lat_val <= 0:\n",
    "        return \"South\" \n",
    "    else:\n",
    "        return \"North\"\n",
    "\n",
    "circuits[\"hemisphere\"] = circuits[\"lat\"].apply(check_hemisphere)\n",
    "\n",
    "# Q: What error did I make?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the column to verify the next cell actually works\n",
    "circuits[\"hemisphere\"] = \"N/A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Pandas function called \".cut\", which you can use to segment data\n",
    "# into intervals or \"bins\" \n",
    "\n",
    "lat_bins = [-90, 0, 90]\n",
    "# lat_bins = [float(\"-inf\"), 0, float(\"inf\")]\n",
    "\n",
    "lat_labels = [\"South\", \"North\"]\n",
    "circuits[\"hemisphere\"] = pd.cut(circuits[\"lat\"], \n",
    "                                bins = lat_bins,\n",
    "                                right = True,\n",
    "                                labels = lat_labels)\n",
    "\n",
    "\n",
    "# Note: if we set lat_bins = [float(\"-inf\"), 0, float(\"inf\")]\n",
    "# then intervals are \"Less than or equal to 0\" and \"Above 0\"\n",
    "# float(\"inf\") and float(\"-inf\") represent positive infinity and negative infinity\n",
    "# The \"right\" command indicates that the right interval is *inclusive*,\n",
    "# i.e. \"less than or equal to\"\n",
    "                            \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"4\">\n",
    "\n",
    "**Exercise:** Recode the altitude variable into a categorial variable with the values\n",
    "\n",
    "- \"Low altitude\" if $\\textrm{altitude} \\leq 45$\n",
    "- \"Medium altitude\" if $45 < \\textrm{altitude} \\leq 145$\n",
    "- \"High altitude\" if $145 < \\textrm{altitude}$\n",
    "\n",
    "**Hint**: Should you use the original altitude column or the one we cleaned?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"4\">\n",
    "\n",
    "**Exercise:** What happens if you use the ``Pandas`` function ``.cut`` if the bins you provide don't capture all the data in the column? What happens if there are missing values in the column? Test it out by recoding the altitude\n",
    "\n",
    "- \"Group A\" if $0 < \\textrm{altitude} \\leq 120$\n",
    "- \"Group B\" if $120 < \\textrm{altitude} \\leq 400$\n",
    "- \"Group C\" if $400 < \\textrm{altitude} \\leq 800$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your own code\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "45fc1f684f6f416f40889115beff3ddf69879b64cf4bfee48cb72a61e9d15d1a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
