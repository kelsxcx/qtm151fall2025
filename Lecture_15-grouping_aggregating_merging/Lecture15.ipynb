{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3dbf9759",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\"> Lecture 15 - Grouping, Aggregating, & Merging Data </span>\n",
    "\n",
    "<font size = \"4\">\n",
    "\n",
    "In the previous class we covered\n",
    "\n",
    "- Missing values\n",
    "- The basics of data cleaning\n",
    "\n",
    "This class we will talk about \n",
    "- Extracting groups of a dataset\n",
    "- Computing aggregate statistics by group\n",
    "- Merging datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0510b7",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\"> I. Grouping </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cd1890f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bbcdc8",
   "metadata": {},
   "source": [
    "<font size = \"4\">\n",
    "We will use the Formula One datasets, stored in the folder \"f1_data_raw\". \n",
    "<br>\n",
    "\n",
    "[See Data Source](https://www.kaggle.com/datasets/rohanrao/formula-1-world-championship-1950-2020)\n",
    "<br>\n",
    "\n",
    "We'll begin with \"results.csv\". Using ``.dtypes`` allows us to see all the column headings, along with their data-types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf92cf7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resultId             int64\n",
      "raceId               int64\n",
      "driverId             int64\n",
      "constructorId        int64\n",
      "number              object\n",
      "grid                 int64\n",
      "position            object\n",
      "positionText        object\n",
      "positionOrder        int64\n",
      "points             float64\n",
      "laps                 int64\n",
      "time                object\n",
      "milliseconds        object\n",
      "fastestLap          object\n",
      "rank                object\n",
      "fastestLapTime      object\n",
      "fastestLapSpeed     object\n",
      "statusId             int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df_results = pd.read_csv(\"f1_data_raw/results.csv\")\n",
    "print(df_results.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6111d153",
   "metadata": {},
   "source": [
    "<font size = \"4\">\n",
    "\n",
    "There are 5 \"ID\" columns, resultId, raceId, driverId, constructorId, statusId.\n",
    "\n",
    "\n",
    "Let's check how how many rows there are in the dataset, and how many **unique** values of these ID's there are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d9ff37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 25660\n",
      "Unique resultId: 25660\n",
      "Unique raceId: 1070\n",
      "Unique driverId: 854\n",
      "Unique constructorId: 210\n",
      "Unique statusId: 137\n"
     ]
    }
   ],
   "source": [
    "# We've used .shape in the past. \n",
    "# But the \"len\" function works too\n",
    "# The last two show other alternatives\n",
    "print(\"Number of rows:\", len(df_results))\n",
    "print(\"Unique resultId:\", len(pd.unique(df_results[\"resultId\"])))\n",
    "print(\"Unique raceId:\", len(pd.unique(df_results[\"raceId\"])))\n",
    "print(\"Unique driverId:\", len(pd.unique(df_results[\"driverId\"])))\n",
    "print(\"Unique constructorId:\", len(df_results[\"constructorId\"].unique()))\n",
    "print(\"Unique statusId:\", df_results[\"statusId\"].nunique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba64999c",
   "metadata": {},
   "source": [
    "<font size = \"4\">\n",
    "\n",
    "Based on a driver's finish, a certain number of points is assigned, which corresponds to the \"points\" column.\n",
    "\n",
    "\n",
    "We could, for example, compute the mean of this column to compute the average number of points per result. This doesn't seem like a very interesting statistic however.\n",
    "\n",
    "But, if we could compute the average points for each driver, or each constructor (the entity which built the car). This would give us important information: which drivers/cars perform the best.\n",
    "\n",
    "We can do this in Pandas using the ``.groupby`` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15714914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.groupby.generic.DataFrameGroupBy'>\n",
      "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x0000021668005E80>\n"
     ]
    }
   ],
   "source": [
    "driver_group = df_results.groupby(by = \"driverId\")\n",
    "constructor_group = df_results.groupby(by = \"constructorId\")\n",
    "\n",
    "# First question to always ask with a new function:\n",
    "# what kind of thing does it output?\n",
    "print(type(driver_group))\n",
    "\n",
    "# 2nd: what does it look like?\n",
    "print(driver_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6785d0de",
   "metadata": {},
   "source": [
    "<font size = \"4\">\n",
    "\n",
    "This returns a \"DataFrameGroupBy\" object, and printing it gives no information (just like for ``range`` and ``zip``).\n",
    "\n",
    "When you do ``range(10)`` it does **not** create an object with the numbers 0, 1, 2, ..., 8, 9. It creates a range object that \"knows\" how to generate the integers from 0 to 9 one-by-one. It doesn't generate these numbers until they are needed, such as a for loop.\n",
    "\n",
    "When you do ``zip(list_1, list_2)`` it does **not** create an object containing all the pairs between the lists. It creates a zip object that \"knows\" how to generate the pairs one-by-one. It doesn't generate these pairs until they are needed, such as a for loop. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed13b857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'zip'>\n",
      "<zip object at 0x000002166832A880>\n"
     ]
    }
   ],
   "source": [
    "list_1 = [5.3, \"Pandas\", -9]\n",
    "list_2 = [\"Number\", 0, 12]\n",
    "\n",
    "zip_lists = zip(list_1, list_2)\n",
    "\n",
    "\n",
    "print(type(zip_lists))\n",
    "print(zip_lists)\n",
    "\n",
    "# The variable zip_lists is \"associated\" or \"linked\" \n",
    "# with the original lists. It draws the elements from \n",
    "# those lists when needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1980566",
   "metadata": {},
   "source": [
    "<font size = \"4\">\n",
    "\n",
    "Similarly, a DataFrameGroupBy object is \"associated\" or \"linked\" with the original DataFrame object. To get something useful, we need to specify:\n",
    "\n",
    "- Column/variable\n",
    "- An operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "968ecf91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "driverId\n",
      "1      14.313953\n",
      "2       1.407609\n",
      "3       7.740291\n",
      "4       5.790831\n",
      "5       0.937500\n",
      "         ...    \n",
      "851     0.000000\n",
      "852     1.228571\n",
      "853     0.000000\n",
      "854     0.342857\n",
      "855     0.384615\n",
      "Name: points, Length: 854, dtype: float64\n",
      "\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# Choose \"points\" and compute its average\n",
    "driver_mean_points = driver_group[\"points\"].mean()\n",
    "print(driver_mean_points)\n",
    "print()\n",
    "print(type(driver_mean_points))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996976e6",
   "metadata": {},
   "source": [
    "<font size = \"4\">\n",
    "\n",
    "We can see that \"Driver 1\" scores an average of 14.31 points per race. Driver 2 only scores an average of 1.41 points per race.\n",
    "\n",
    "Let's grab the 5 top performing drivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3609885d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "driverId\n",
      "1      14.313953\n",
      "830    11.639610\n",
      "20     10.573883\n",
      "822     9.244792\n",
      "3       7.740291\n",
      "Name: points, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "mean_pts_sorted = driver_mean_points.sort_values(ascending = False)\n",
    "\n",
    "# This is a *Series*. Only needs one integer (or range of integers).\n",
    "# A DataFrame needs two integers (row and column)\n",
    "print(mean_pts_sorted.iloc[:5]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0ba9f4",
   "metadata": {},
   "source": [
    "<font size = \"4\">\n",
    "\n",
    "To go from driverId to the driver's name, you would need to use \"drivers.csv\". The best performing driver (with driverId 1) is Lewis Hamilton\n",
    "<br>\n",
    "\n",
    "Could also compute the mean of both \"points\" and \"positionOrder\" (since they are both numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "908bdf7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             points  positionOrder\n",
      "driverId                          \n",
      "1         14.313953       4.707641\n",
      "2          1.407609      10.722826\n",
      "3          7.740291       8.252427\n",
      "4          5.790831       8.409742\n",
      "5          0.937500      13.285714\n",
      "...             ...            ...\n",
      "851        0.000000      16.000000\n",
      "852        1.228571      13.657143\n",
      "853        0.000000      17.863636\n",
      "854        0.342857      15.914286\n",
      "855        0.384615      14.615385\n",
      "\n",
      "[854 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "mean_pts_position = driver_group[[\"points\", \"positionOrder\"]].mean()\n",
    "print(mean_pts_position)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5bbc3d",
   "metadata": {},
   "source": [
    "<font size = \"4\">\n",
    "\n",
    "Can \"chain\" together all the commands instead of breaking them up into single lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af42c83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "driverId\n",
      "1      14.313953\n",
      "830    11.639610\n",
      "20     10.573883\n",
      "822     9.244792\n",
      "3       7.740291\n",
      "Name: points, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#### Starting with the DataFrame, we did the following steps to get\n",
    "#### the top 5 performers:\n",
    "\n",
    "# driver_group = df_results.groupby(by = \"driverId\")\n",
    "# driver_mean_points = driver_group[\"points\"].mean()\n",
    "# mean_pts_sorted = driver_mean_points.sort_values(ascending = False)\n",
    "# print(mean_pts_sorted.iloc[:5])\n",
    "\n",
    "\n",
    "top5_one_line = df_results.groupby(by = \"driverId\")[\"points\"].mean().sort_values(ascending=False).iloc[:5]\n",
    "print(top5_one_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d108662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "driverId\n",
      "1      14.313953\n",
      "830    11.639610\n",
      "20     10.573883\n",
      "822     9.244792\n",
      "3       7.740291\n",
      "Name: points, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# It's considered good practice to make each line less than 80 characters\n",
    "# This makes it easier to scroll up and down without going sideways.\n",
    "# Can use the backslash (\\) for a new line\n",
    "\n",
    "top5_one_line = df_results.groupby(by = \"driverId\")[\"points\"].mean().\\\n",
    "    sort_values(ascending=False).iloc[:5]\n",
    "print(top5_one_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9044dbd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "driverId\n",
      "1      14.313953\n",
      "830    11.639610\n",
      "20     10.573883\n",
      "822     9.244792\n",
      "3       7.740291\n",
      "Name: points, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Can also add parentheses around everything on the right\n",
    "# Then can use multiple lines\n",
    "\n",
    "top5_one_line = (df_results.groupby(by = \"driverId\")[\"points\"].mean().\n",
    "    sort_values(ascending=False).iloc[:5])\n",
    "print(top5_one_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e705f4e",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\"> II. Aggregating Statistics </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81c8119",
   "metadata": {},
   "source": [
    "<font size = \"4\">\n",
    "\n",
    "Suppose we want to compute the mean, standard deviation, minimum, and maximum of \"points\" for the entire dataset\n",
    "\n",
    "Most straightforward way is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56d09d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_col = df_results[\"points\"]\n",
    "pts_mean = pts_col.mean()\n",
    "pts_std = pts_col.std()\n",
    "pts_min = pts_col.min()\n",
    "pts_max = pts_col.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64965d64",
   "metadata": {},
   "source": [
    "<font size = \"4\">\n",
    "\n",
    "Can compute these in one command using ``.agg`` (which stands for aggregate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c09f3b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean     1.854523\n",
      "std      4.131527\n",
      "min      0.000000\n",
      "max     50.000000\n",
      "Name: points, dtype: float64\n",
      "\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "pts_col = df_results[\"points\"]\n",
    "\n",
    "pts_stats = pts_col.agg([\"mean\", \"std\", \"min\", \"max\"])\n",
    "\n",
    "print(pts_stats)\n",
    "print()\n",
    "print(type(pts_stats))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326e64f7",
   "metadata": {},
   "source": [
    "<font size = \"4\">\n",
    "\n",
    "The ``.agg`` function is very flexible. By rule, the more flexible a function is, the harder it is to learn. \n",
    "\n",
    "Both Pandas Series and DataFrames have a method called `.agg`. If you type ``help(df_results.agg)``, you will see the documentation, along with some very simple examples.\n",
    "\n",
    "Note that the examples for ``help(pts_col.agg)`` will be different, because it is a **Series**, while \"df_results\" is a **DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13d04b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method aggregate in module pandas.core.frame:\n",
      "\n",
      "aggregate(func=None, axis: 'Axis' = 0, *args, **kwargs) method of pandas.core.frame.DataFrame instance\n",
      "    Aggregate using one or more operations over the specified axis.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    func : function, str, list or dict\n",
      "        Function to use for aggregating the data. If a function, must either\n",
      "        work when passed a DataFrame or when passed to DataFrame.apply.\n",
      "\n",
      "        Accepted combinations are:\n",
      "\n",
      "        - function\n",
      "        - string function name\n",
      "        - list of functions and/or function names, e.g. ``[np.sum, 'mean']``\n",
      "        - dict of axis labels -> functions, function names or list of such.\n",
      "    axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      "            If 0 or 'index': apply function to each column.\n",
      "            If 1 or 'columns': apply function to each row.\n",
      "    *args\n",
      "        Positional arguments to pass to `func`.\n",
      "    **kwargs\n",
      "        Keyword arguments to pass to `func`.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    scalar, Series or DataFrame\n",
      "\n",
      "        The return can be:\n",
      "\n",
      "        * scalar : when Series.agg is called with single function\n",
      "        * Series : when DataFrame.agg is called with a single function\n",
      "        * DataFrame : when DataFrame.agg is called with several functions\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    DataFrame.apply : Perform any type of operations.\n",
      "    DataFrame.transform : Perform transformation type operations.\n",
      "    pandas.DataFrame.groupby : Perform operations over groups.\n",
      "    pandas.DataFrame.resample : Perform operations over resampled bins.\n",
      "    pandas.DataFrame.rolling : Perform operations over rolling window.\n",
      "    pandas.DataFrame.expanding : Perform operations over expanding window.\n",
      "    pandas.core.window.ewm.ExponentialMovingWindow : Perform operation over exponential\n",
      "        weighted window.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    The aggregation operations are always performed over an axis, either the\n",
      "    index (default) or the column axis. This behavior is different from\n",
      "    `numpy` aggregation functions (`mean`, `median`, `prod`, `sum`, `std`,\n",
      "    `var`), where the default is to compute the aggregation of the flattened\n",
      "    array, e.g., ``numpy.mean(arr_2d)`` as opposed to\n",
      "    ``numpy.mean(arr_2d, axis=0)``.\n",
      "\n",
      "    `agg` is an alias for `aggregate`. Use the alias.\n",
      "\n",
      "    Functions that mutate the passed object can produce unexpected\n",
      "    behavior or errors and are not supported. See :ref:`gotchas.udf-mutation`\n",
      "    for more details.\n",
      "\n",
      "    A passed user-defined-function will be passed a Series for evaluation.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> df = pd.DataFrame([[1, 2, 3],\n",
      "    ...                    [4, 5, 6],\n",
      "    ...                    [7, 8, 9],\n",
      "    ...                    [np.nan, np.nan, np.nan]],\n",
      "    ...                   columns=['A', 'B', 'C'])\n",
      "\n",
      "    Aggregate these functions over the rows.\n",
      "\n",
      "    >>> df.agg(['sum', 'min'])\n",
      "            A     B     C\n",
      "    sum  12.0  15.0  18.0\n",
      "    min   1.0   2.0   3.0\n",
      "\n",
      "    Different aggregations per column.\n",
      "\n",
      "    >>> df.agg({'A' : ['sum', 'min'], 'B' : ['min', 'max']})\n",
      "            A    B\n",
      "    sum  12.0  NaN\n",
      "    min   1.0  2.0\n",
      "    max   NaN  8.0\n",
      "\n",
      "    Aggregate different functions over the columns and rename the index of the resulting\n",
      "    DataFrame.\n",
      "\n",
      "    >>> df.agg(x=('A', 'max'), y=('B', 'min'), z=('C', 'mean'))\n",
      "         A    B    C\n",
      "    x  7.0  NaN  NaN\n",
      "    y  NaN  2.0  NaN\n",
      "    z  NaN  NaN  6.0\n",
      "\n",
      "    Aggregate over the columns.\n",
      "\n",
      "    >>> df.agg(\"mean\", axis=\"columns\")\n",
      "    0    2.0\n",
      "    1    5.0\n",
      "    2    8.0\n",
      "    3    NaN\n",
      "    dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(df_results.agg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f61d3e7",
   "metadata": {},
   "source": [
    "<font size = \"4\">\n",
    "\n",
    "Let's look at the examples for a DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0291fc9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B    C\n",
      "0  1.0  2.0  3.0\n",
      "1  4.0  5.0  6.0\n",
      "2  7.0  8.0  9.0\n",
      "3  NaN  NaN  NaN\n"
     ]
    }
   ],
   "source": [
    "df_example = pd.DataFrame([[1, 2, 3],\n",
    "                           [4, 5, 6],\n",
    "                           [7, 8, 9], \n",
    "                           [np.nan, np.nan, np.nan]], \n",
    "                           columns=['A', 'B', 'C'])\n",
    "print(df_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55c2acfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        A     B     C\n",
      "sum  12.0  15.0  18.0\n",
      "min   1.0   2.0   3.0\n"
     ]
    }
   ],
   "source": [
    "# Aggregate the sum and minimum functions over the rows\n",
    "example_1 = df_example.agg([\"sum\", \"min\"])\n",
    "print(example_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eff520a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        A    B\n",
      "sum  12.0  NaN\n",
      "min   1.0  2.0\n",
      "max   NaN  8.0\n"
     ]
    }
   ],
   "source": [
    "# Different aggregations per column\n",
    "example_2 = df_example.agg({'A' : ['sum', 'min'], 'B' : ['min', 'max']})\n",
    "print(example_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "020a4992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B    C\n",
      "x  7.0  NaN  NaN\n",
      "y  NaN  2.0  NaN\n",
      "z  NaN  NaN  6.0\n"
     ]
    }
   ],
   "source": [
    "# Aggregate different functions over the columns \n",
    "# and rename the index of the resulting DataFrame.\n",
    "example_3 = df_example.agg(x = ('A', 'max'),\n",
    "                           y = ('B', 'min'),\n",
    "                           z = ('C', 'mean'))\n",
    "\n",
    "print(example_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77049833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate over the columns\n",
    "example_4 = df_example.agg(\"mean\", axis=\"columns\")\n",
    "print(example_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3832847",
   "metadata": {},
   "source": [
    "<font size = \"4\">\n",
    "\n",
    "With these examples in mind, we can return to our original DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6e99de",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_agg = df_results.agg(mean_points = ('points','mean'),\n",
    "                          sd_points =   ('points','std'),\n",
    "                          min_points =  ('points','min'),\n",
    "                          max_points =  ('points','max'))\n",
    "\n",
    "print(results_agg)\n",
    "results_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b616f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_unique = lambda col: len(col.unique())\n",
    "results_agg = df_results.agg(mean_points = ('points','mean'),\n",
    "                          mean_laps =   ('laps','mean'),\n",
    "                          min_points =  ('points','min'),\n",
    "                          max_points =  ('points','max'),\n",
    "                          num_drivers = ('driverId', count_unique))\n",
    "\n",
    "print(results_agg)\n",
    "results_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf09d71",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\"> III. Grouping + Aggregating </span>\n",
    "\n",
    "\n",
    "<img src=\"figures/agg.png\" alt=\"drawing\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508f5e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "drivers_agg = (df_results.groupby(\"driverId\")\n",
    "                      .agg(mean_points = ('points','mean'),\n",
    "                           sd_points =   ('points','std'),\n",
    "                           min_points =  ('points','min'),\n",
    "                           max_points =  ('points','max'),\n",
    "                           appearances   = ('points',len)))\n",
    "\n",
    "print(type(drivers_agg))\n",
    "print(drivers_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb650f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# driverId is the \"Index\" column, NOT a regular column\n",
    "print(drivers_agg.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67c0e72",
   "metadata": {},
   "source": [
    "<font size = \"4\" >\n",
    "\n",
    "Groupby + Aggregate statistics (multigroup)\n",
    "\n",
    "Each constructor can have multiple vehicles competing in a given race. We'll group by Race ID and Constructor ID, then aggregate statistics. This will allow us to see how each constructor did relative to the others in a given race."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee95c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "teamrace_agg = (df_results.groupby(  [\"raceId\",\"constructorId\"]    )\n",
    "                       .agg(mean_points = ('points','mean'),\n",
    "                            sd_points =   ('points','std'),\n",
    "                            min_points =  ('points','min'),\n",
    "                            max_points =  ('points','max'),\n",
    "                            cars_entered   = ('points',len)))\n",
    "\n",
    "print(teamrace_agg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0652e9",
   "metadata": {},
   "source": [
    "<font size = \"4\">\n",
    "\n",
    "Filtering + Grouping + Aggregating: <br>\n",
    "\n",
    "```python \n",
    ".query().groupby().agg()\n",
    "```\n",
    "\n",
    "- Another example of \"chaining\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39c04aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following gets a subset of the data using .query()\n",
    "# In this case we subset the data before computing aggregate statistics\n",
    "# Note: \"filtering\" is often the word used to obtain a subset\n",
    "\n",
    "teamrace_agg = (df_results.query(\"raceId >= 500\")\n",
    "                       .groupby([\"raceId\",\"constructorId\"])\n",
    "                        .agg(mean_points = ('points','mean'),\n",
    "                             sd_points =   ('points','std'),\n",
    "                             min_points =  ('points','min'),\n",
    "                             max_points =  ('points','max'),\n",
    "                             cars_entered   = ('points',len)))\n",
    "teamrace_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcee5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe we're only interested in the mean\n",
    "(df_results.query(\"raceId >= 500\").groupby([\"raceId\",\"constructorId\"]).\n",
    " agg(mean_points = ('points','mean')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d800dd",
   "metadata": {},
   "source": [
    "<font size = \"4\">\n",
    "\n",
    "**Exercise:** Perform the following by chaining. Create a DataFrame where for each race (identified by \"raceId\") we aggregate the average number of laps and the average number of points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df2ae4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846f6816",
   "metadata": {},
   "source": [
    "<font size = \"4\">\n",
    "\n",
    "**Exercise:** Perform the following by chaining. For each constructor (identified by \"constructorId\"), aggregate the average number of points, then sort in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abaa183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6054c49",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\"> IV. Merging </span>\n",
    "\n",
    "\n",
    "<img src=\"figures/merge_stats.png\" alt=\"drawing\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e005ac",
   "metadata": {},
   "source": [
    "<font size = \"4\">\n",
    "\n",
    "We have the original DataFrame (\"df_results\"), and we have aggregate statistics for each driver (\"drivers_agg\"). We'll merge these two together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26b4882",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0078eb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "drivers_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bbd4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This command merges the \"aggregate\" information in \"driver_agg\" into\n",
    "# \"df_results\" similar as the figure above.\n",
    "# The merging variable \"on\" is determined by \"driverId\", which is a column\n",
    "# that is common to both DataFrames\n",
    "# \"how = left\" indicates that the left DataFrame is the baseline\n",
    "\n",
    "results_merge = pd.merge(df_results,\n",
    "                         drivers_agg,\n",
    "                         on = \"driverId\",\n",
    "                         how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d50551",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_merge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2999366b",
   "metadata": {},
   "source": [
    "<font size = \"4\">\n",
    "\n",
    "**Exercise:** Compute a scatter plot of \"points\" (horizontal axis) vs. \"mean_points\" (vertical axis). This plot tries to describe how much a driver's performance in individual races deviates from their overall average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4c11ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90032b9",
   "metadata": {},
   "source": [
    "<font size = \"4\">\n",
    "\n",
    "**Exercise:** Merge the \"teamrace_agg\" data into \"df_results\". This time use the option:\n",
    "\n",
    "```python\n",
    "        on = [\"raceId\",\"constructorId\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50203c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
